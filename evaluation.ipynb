{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "future-generic",
   "metadata": {},
   "source": [
    "# Evaluation of a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "altered-clothing",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Read in config file\\nconfig_name = [\"bowles2021mirabest.cfg\", \\n               \"bowles2021mingo.cfg\", \\n               \"scaife2021mirabestDN.cfg\", \\n               \"scaife2021mingo.cfg\", \\n               \"e2attentionmirabest.cfg\"\\n              ]\\nconfig_name = \"configs/\"+config_name[-1]\\nconfig = ConfigParser.ConfigParser(allow_no_value=True)\\nconfig.read(config_name)\\n\\n# Load network architecture (with random weights)\\nprint(f\"Loading in {config[\\'model\\'][\\'base\\']}\")\\nnet = locals()[config[\\'model\\'][\\'base\\']](**config[\\'model\\']).to(device)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import e2cnn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import PIL\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import configparser as ConfigParser\n",
    "\n",
    "import utils\n",
    "# Ipmport various network architectures\n",
    "from networks import AGRadGalNet, DNSteerableLeNet, DNSteerableAGRadGalNet #e2cnn module only works in python3.7+\n",
    "# Import various data classes\n",
    "from datasets import FRDEEPF\n",
    "from datasets import MiraBest_full, MBFRConfident, MBFRUncertain, MBHybrid\n",
    "from datasets import MingoLoTSS, MLFR, MLFRTest\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "\n",
    "# Set seeds for reproduceability\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Get correct device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\"\"\"# Read in config file\n",
    "config_name = [\"bowles2021mirabest.cfg\", \n",
    "               \"bowles2021mingo.cfg\", \n",
    "               \"scaife2021mirabestDN.cfg\", \n",
    "               \"scaife2021mingo.cfg\", \n",
    "               \"e2attentionmirabest.cfg\"\n",
    "              ]\n",
    "config_name = \"configs/\"+config_name[-1]\n",
    "config = ConfigParser.ConfigParser(allow_no_value=True)\n",
    "config.read(config_name)\n",
    "\n",
    "# Load network architecture (with random weights)\n",
    "print(f\"Loading in {config['model']['base']}\")\n",
    "net = locals()[config['model']['base']](**config['model']).to(device)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amazing-spider",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4_attention_mirabest.cfg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:61: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  sampled_basis = sampled_basis[mask, ...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating C4_attention_mirabest.cfg: models/e2attention/mirabest/fisher/C4/random rotation\tMBFRUncertain\trandom rotation\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/torchvision/transforms/transforms.py:1314: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
      "  warnings.warn(\n",
      "/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/torch/nn/functional.py:3451: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating C4_attention_mirabest.cfg: models/e2attention/mirabest/fisher/C4/random rotation\tMLFR\trandom rotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/torchvision/transforms/transforms.py:1314: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/torch/nn/functional.py:3451: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D8_attention_mirabest.cfg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:61: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  sampled_basis = sampled_basis[mask, ...]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DNSteerableAGRadGalNet:\n\tMissing key(s) in state_dict: \"conv1a._basisexpansion.block_expansion_('irrep_0,0', 'regular').sampled_basis\", \"bnorm1a.indices_16\", \"bnorm1a.batch_norm_[16].weight\", \"bnorm1a.batch_norm_[16].bias\", \"bnorm1a.batch_norm_[16].running_mean\", \"bnorm1a.batch_norm_[16].running_var\", \"conv1b._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm1b.indices_16\", \"bnorm1b.batch_norm_[16].weight\", \"bnorm1b.batch_norm_[16].bias\", \"bnorm1b.batch_norm_[16].running_mean\", \"bnorm1b.batch_norm_[16].running_var\", \"conv1c._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm1c.indices_16\", \"bnorm1c.batch_norm_[16].weight\", \"bnorm1c.batch_norm_[16].bias\", \"bnorm1c.batch_norm_[16].running_mean\", \"bnorm1c.batch_norm_[16].running_var\", \"gpool1.in_indices_16\", \"gpool1.out_indices_16\", \"conv2a._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm2a.indices_16\", \"bnorm2a.batch_norm_[16].weight\", \"bnorm2a.batch_norm_[16].bias\", \"bnorm2a.batch_norm_[16].running_mean\", \"bnorm2a.batch_norm_[16].running_var\", \"conv2b._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm2b.indices_16\", \"bnorm2b.batch_norm_[16].weight\", \"bnorm2b.batch_norm_[16].bias\", \"bnorm2b.batch_norm_[16].running_mean\", \"bnorm2b.batch_norm_[16].running_var\", \"conv2c._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm2c.indices_16\", \"bnorm2c.batch_norm_[16].weight\", \"bnorm2c.batch_norm_[16].bias\", \"bnorm2c.batch_norm_[16].running_mean\", \"bnorm2c.batch_norm_[16].running_var\", \"gpool2.in_indices_16\", \"gpool2.out_indices_16\", \"conv3a._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm3a.indices_16\", \"bnorm3a.batch_norm_[16].weight\", \"bnorm3a.batch_norm_[16].bias\", \"bnorm3a.batch_norm_[16].running_mean\", \"bnorm3a.batch_norm_[16].running_var\", \"conv3b._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm3b.indices_16\", \"bnorm3b.batch_norm_[16].weight\", \"bnorm3b.batch_norm_[16].bias\", \"bnorm3b.batch_norm_[16].running_mean\", \"bnorm3b.batch_norm_[16].running_var\", \"conv3c._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm3c.indices_16\", \"bnorm3c.batch_norm_[16].weight\", \"bnorm3c.batch_norm_[16].bias\", \"bnorm3c.batch_norm_[16].running_mean\", \"bnorm3c.batch_norm_[16].running_var\", \"gpool3.in_indices_16\", \"gpool3.out_indices_16\", \"conv4a._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm4a.indices_16\", \"bnorm4a.batch_norm_[16].weight\", \"bnorm4a.batch_norm_[16].bias\", \"bnorm4a.batch_norm_[16].running_mean\", \"bnorm4a.batch_norm_[16].running_var\", \"conv4b._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm4b.indices_16\", \"bnorm4b.batch_norm_[16].weight\", \"bnorm4b.batch_norm_[16].bias\", \"bnorm4b.batch_norm_[16].running_mean\", \"bnorm4b.batch_norm_[16].running_var\", \"gpool4.in_indices_16\", \"gpool4.out_indices_16\". \n\tUnexpected key(s) in state_dict: \"conv1a._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm1a.indices_1\", \"bnorm1a.batch_norm_[1].weight\", \"bnorm1a.batch_norm_[1].bias\", \"bnorm1a.batch_norm_[1].running_mean\", \"bnorm1a.batch_norm_[1].running_var\", \"bnorm1a.batch_norm_[1].num_batches_tracked\", \"conv1b._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm1b.indices_1\", \"bnorm1b.batch_norm_[1].weight\", \"bnorm1b.batch_norm_[1].bias\", \"bnorm1b.batch_norm_[1].running_mean\", \"bnorm1b.batch_norm_[1].running_var\", \"bnorm1b.batch_norm_[1].num_batches_tracked\", \"conv1c._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm1c.indices_1\", \"bnorm1c.batch_norm_[1].weight\", \"bnorm1c.batch_norm_[1].bias\", \"bnorm1c.batch_norm_[1].running_mean\", \"bnorm1c.batch_norm_[1].running_var\", \"bnorm1c.batch_norm_[1].num_batches_tracked\", \"conv2a._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm2a.indices_1\", \"bnorm2a.batch_norm_[1].weight\", \"bnorm2a.batch_norm_[1].bias\", \"bnorm2a.batch_norm_[1].running_mean\", \"bnorm2a.batch_norm_[1].running_var\", \"bnorm2a.batch_norm_[1].num_batches_tracked\", \"conv2b._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm2b.indices_1\", \"bnorm2b.batch_norm_[1].weight\", \"bnorm2b.batch_norm_[1].bias\", \"bnorm2b.batch_norm_[1].running_mean\", \"bnorm2b.batch_norm_[1].running_var\", \"bnorm2b.batch_norm_[1].num_batches_tracked\", \"conv2c._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm2c.indices_1\", \"bnorm2c.batch_norm_[1].weight\", \"bnorm2c.batch_norm_[1].bias\", \"bnorm2c.batch_norm_[1].running_mean\", \"bnorm2c.batch_norm_[1].running_var\", \"bnorm2c.batch_norm_[1].num_batches_tracked\", \"conv3a._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm3a.indices_1\", \"bnorm3a.batch_norm_[1].weight\", \"bnorm3a.batch_norm_[1].bias\", \"bnorm3a.batch_norm_[1].running_mean\", \"bnorm3a.batch_norm_[1].running_var\", \"bnorm3a.batch_norm_[1].num_batches_tracked\", \"conv3b._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm3b.indices_1\", \"bnorm3b.batch_norm_[1].weight\", \"bnorm3b.batch_norm_[1].bias\", \"bnorm3b.batch_norm_[1].running_mean\", \"bnorm3b.batch_norm_[1].running_var\", \"bnorm3b.batch_norm_[1].num_batches_tracked\", \"conv3c._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm3c.indices_1\", \"bnorm3c.batch_norm_[1].weight\", \"bnorm3c.batch_norm_[1].bias\", \"bnorm3c.batch_norm_[1].running_mean\", \"bnorm3c.batch_norm_[1].running_var\", \"bnorm3c.batch_norm_[1].num_batches_tracked\", \"conv4a._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm4a.indices_1\", \"bnorm4a.batch_norm_[1].weight\", \"bnorm4a.batch_norm_[1].bias\", \"bnorm4a.batch_norm_[1].running_mean\", \"bnorm4a.batch_norm_[1].running_var\", \"bnorm4a.batch_norm_[1].num_batches_tracked\", \"conv4b._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm4b.indices_1\", \"bnorm4b.batch_norm_[1].weight\", \"bnorm4b.batch_norm_[1].bias\", \"bnorm4b.batch_norm_[1].running_mean\", \"bnorm4b.batch_norm_[1].running_var\", \"bnorm4b.batch_norm_[1].num_batches_tracked\". \n\tsize mismatch for conv1a.weights: copying a param with shape torch.Size([18]) from checkpoint, the shape in current model is torch.Size([66]).\n\tsize mismatch for conv1a.filter: copying a param with shape torch.Size([6, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([96, 1, 5, 5]).\n\tsize mismatch for conv1b.weights: copying a param with shape torch.Size([108]) from checkpoint, the shape in current model is torch.Size([6336]).\n\tsize mismatch for conv1b.filter: copying a param with shape torch.Size([6, 6, 5, 5]) from checkpoint, the shape in current model is torch.Size([96, 96, 5, 5]).\n\tsize mismatch for conv1c.weights: copying a param with shape torch.Size([108]) from checkpoint, the shape in current model is torch.Size([6336]).\n\tsize mismatch for conv1c.filter: copying a param with shape torch.Size([6, 6, 5, 5]) from checkpoint, the shape in current model is torch.Size([96, 96, 5, 5]).\n\tsize mismatch for conv2a.weights: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([16896]).\n\tsize mismatch for conv2a.filter: copying a param with shape torch.Size([16, 6, 5, 5]) from checkpoint, the shape in current model is torch.Size([256, 96, 5, 5]).\n\tsize mismatch for conv2b.weights: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([45056]).\n\tsize mismatch for conv2b.filter: copying a param with shape torch.Size([16, 16, 5, 5]) from checkpoint, the shape in current model is torch.Size([256, 256, 5, 5]).\n\tsize mismatch for conv2c.weights: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([45056]).\n\tsize mismatch for conv2c.filter: copying a param with shape torch.Size([16, 16, 5, 5]) from checkpoint, the shape in current model is torch.Size([256, 256, 5, 5]).\n\tsize mismatch for conv3a.weights: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([90112]).\n\tsize mismatch for conv3a.filter: copying a param with shape torch.Size([32, 16, 5, 5]) from checkpoint, the shape in current model is torch.Size([512, 256, 5, 5]).\n\tsize mismatch for conv3b.weights: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([180224]).\n\tsize mismatch for conv3b.filter: copying a param with shape torch.Size([32, 32, 5, 5]) from checkpoint, the shape in current model is torch.Size([512, 512, 5, 5]).\n\tsize mismatch for conv3c.weights: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([180224]).\n\tsize mismatch for conv3c.filter: copying a param with shape torch.Size([32, 32, 5, 5]) from checkpoint, the shape in current model is torch.Size([512, 512, 5, 5]).\n\tsize mismatch for conv4a.weights: copying a param with shape torch.Size([6144]) from checkpoint, the shape in current model is torch.Size([360448]).\n\tsize mismatch for conv4a.filter: copying a param with shape torch.Size([64, 32, 5, 5]) from checkpoint, the shape in current model is torch.Size([1024, 512, 5, 5]).\n\tsize mismatch for conv4b.weights: copying a param with shape torch.Size([12288]) from checkpoint, the shape in current model is torch.Size([720896]).\n\tsize mismatch for conv4b.filter: copying a param with shape torch.Size([64, 64, 5, 5]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 5, 5]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d6f3a18dc8e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maugmentation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maugmentations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mpath_supliment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'augment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_supliment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_supliment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mdata_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'configs/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0md_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Evaluating {cfg}: {config['output']['directory']}/{config['data']['augment']}\\t{data_config['data']['dataset']}\\t{augmentation}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/scratch/mbowles/EquivariantSelfAttention/utils/utils.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(config, load_model, path_supliment, device)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1224\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DNSteerableAGRadGalNet:\n\tMissing key(s) in state_dict: \"conv1a._basisexpansion.block_expansion_('irrep_0,0', 'regular').sampled_basis\", \"bnorm1a.indices_16\", \"bnorm1a.batch_norm_[16].weight\", \"bnorm1a.batch_norm_[16].bias\", \"bnorm1a.batch_norm_[16].running_mean\", \"bnorm1a.batch_norm_[16].running_var\", \"conv1b._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm1b.indices_16\", \"bnorm1b.batch_norm_[16].weight\", \"bnorm1b.batch_norm_[16].bias\", \"bnorm1b.batch_norm_[16].running_mean\", \"bnorm1b.batch_norm_[16].running_var\", \"conv1c._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm1c.indices_16\", \"bnorm1c.batch_norm_[16].weight\", \"bnorm1c.batch_norm_[16].bias\", \"bnorm1c.batch_norm_[16].running_mean\", \"bnorm1c.batch_norm_[16].running_var\", \"gpool1.in_indices_16\", \"gpool1.out_indices_16\", \"conv2a._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm2a.indices_16\", \"bnorm2a.batch_norm_[16].weight\", \"bnorm2a.batch_norm_[16].bias\", \"bnorm2a.batch_norm_[16].running_mean\", \"bnorm2a.batch_norm_[16].running_var\", \"conv2b._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm2b.indices_16\", \"bnorm2b.batch_norm_[16].weight\", \"bnorm2b.batch_norm_[16].bias\", \"bnorm2b.batch_norm_[16].running_mean\", \"bnorm2b.batch_norm_[16].running_var\", \"conv2c._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm2c.indices_16\", \"bnorm2c.batch_norm_[16].weight\", \"bnorm2c.batch_norm_[16].bias\", \"bnorm2c.batch_norm_[16].running_mean\", \"bnorm2c.batch_norm_[16].running_var\", \"gpool2.in_indices_16\", \"gpool2.out_indices_16\", \"conv3a._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm3a.indices_16\", \"bnorm3a.batch_norm_[16].weight\", \"bnorm3a.batch_norm_[16].bias\", \"bnorm3a.batch_norm_[16].running_mean\", \"bnorm3a.batch_norm_[16].running_var\", \"conv3b._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm3b.indices_16\", \"bnorm3b.batch_norm_[16].weight\", \"bnorm3b.batch_norm_[16].bias\", \"bnorm3b.batch_norm_[16].running_mean\", \"bnorm3b.batch_norm_[16].running_var\", \"conv3c._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm3c.indices_16\", \"bnorm3c.batch_norm_[16].weight\", \"bnorm3c.batch_norm_[16].bias\", \"bnorm3c.batch_norm_[16].running_mean\", \"bnorm3c.batch_norm_[16].running_var\", \"gpool3.in_indices_16\", \"gpool3.out_indices_16\", \"conv4a._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm4a.indices_16\", \"bnorm4a.batch_norm_[16].weight\", \"bnorm4a.batch_norm_[16].bias\", \"bnorm4a.batch_norm_[16].running_mean\", \"bnorm4a.batch_norm_[16].running_var\", \"conv4b._basisexpansion.block_expansion_('regular', 'regular').sampled_basis\", \"bnorm4b.indices_16\", \"bnorm4b.batch_norm_[16].weight\", \"bnorm4b.batch_norm_[16].bias\", \"bnorm4b.batch_norm_[16].running_mean\", \"bnorm4b.batch_norm_[16].running_var\", \"gpool4.in_indices_16\", \"gpool4.out_indices_16\". \n\tUnexpected key(s) in state_dict: \"conv1a._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm1a.indices_1\", \"bnorm1a.batch_norm_[1].weight\", \"bnorm1a.batch_norm_[1].bias\", \"bnorm1a.batch_norm_[1].running_mean\", \"bnorm1a.batch_norm_[1].running_var\", \"bnorm1a.batch_norm_[1].num_batches_tracked\", \"conv1b._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm1b.indices_1\", \"bnorm1b.batch_norm_[1].weight\", \"bnorm1b.batch_norm_[1].bias\", \"bnorm1b.batch_norm_[1].running_mean\", \"bnorm1b.batch_norm_[1].running_var\", \"bnorm1b.batch_norm_[1].num_batches_tracked\", \"conv1c._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm1c.indices_1\", \"bnorm1c.batch_norm_[1].weight\", \"bnorm1c.batch_norm_[1].bias\", \"bnorm1c.batch_norm_[1].running_mean\", \"bnorm1c.batch_norm_[1].running_var\", \"bnorm1c.batch_norm_[1].num_batches_tracked\", \"conv2a._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm2a.indices_1\", \"bnorm2a.batch_norm_[1].weight\", \"bnorm2a.batch_norm_[1].bias\", \"bnorm2a.batch_norm_[1].running_mean\", \"bnorm2a.batch_norm_[1].running_var\", \"bnorm2a.batch_norm_[1].num_batches_tracked\", \"conv2b._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm2b.indices_1\", \"bnorm2b.batch_norm_[1].weight\", \"bnorm2b.batch_norm_[1].bias\", \"bnorm2b.batch_norm_[1].running_mean\", \"bnorm2b.batch_norm_[1].running_var\", \"bnorm2b.batch_norm_[1].num_batches_tracked\", \"conv2c._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm2c.indices_1\", \"bnorm2c.batch_norm_[1].weight\", \"bnorm2c.batch_norm_[1].bias\", \"bnorm2c.batch_norm_[1].running_mean\", \"bnorm2c.batch_norm_[1].running_var\", \"bnorm2c.batch_norm_[1].num_batches_tracked\", \"conv3a._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm3a.indices_1\", \"bnorm3a.batch_norm_[1].weight\", \"bnorm3a.batch_norm_[1].bias\", \"bnorm3a.batch_norm_[1].running_mean\", \"bnorm3a.batch_norm_[1].running_var\", \"bnorm3a.batch_norm_[1].num_batches_tracked\", \"conv3b._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm3b.indices_1\", \"bnorm3b.batch_norm_[1].weight\", \"bnorm3b.batch_norm_[1].bias\", \"bnorm3b.batch_norm_[1].running_mean\", \"bnorm3b.batch_norm_[1].running_var\", \"bnorm3b.batch_norm_[1].num_batches_tracked\", \"conv3c._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm3c.indices_1\", \"bnorm3c.batch_norm_[1].weight\", \"bnorm3c.batch_norm_[1].bias\", \"bnorm3c.batch_norm_[1].running_mean\", \"bnorm3c.batch_norm_[1].running_var\", \"bnorm3c.batch_norm_[1].num_batches_tracked\", \"conv4a._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm4a.indices_1\", \"bnorm4a.batch_norm_[1].weight\", \"bnorm4a.batch_norm_[1].bias\", \"bnorm4a.batch_norm_[1].running_mean\", \"bnorm4a.batch_norm_[1].running_var\", \"bnorm4a.batch_norm_[1].num_batches_tracked\", \"conv4b._basisexpansion.block_expansion_('irrep_0,0', 'irrep_0,0').sampled_basis\", \"bnorm4b.indices_1\", \"bnorm4b.batch_norm_[1].weight\", \"bnorm4b.batch_norm_[1].bias\", \"bnorm4b.batch_norm_[1].running_mean\", \"bnorm4b.batch_norm_[1].running_var\", \"bnorm4b.batch_norm_[1].num_batches_tracked\". \n\tsize mismatch for conv1a.weights: copying a param with shape torch.Size([18]) from checkpoint, the shape in current model is torch.Size([66]).\n\tsize mismatch for conv1a.filter: copying a param with shape torch.Size([6, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([96, 1, 5, 5]).\n\tsize mismatch for conv1b.weights: copying a param with shape torch.Size([108]) from checkpoint, the shape in current model is torch.Size([6336]).\n\tsize mismatch for conv1b.filter: copying a param with shape torch.Size([6, 6, 5, 5]) from checkpoint, the shape in current model is torch.Size([96, 96, 5, 5]).\n\tsize mismatch for conv1c.weights: copying a param with shape torch.Size([108]) from checkpoint, the shape in current model is torch.Size([6336]).\n\tsize mismatch for conv1c.filter: copying a param with shape torch.Size([6, 6, 5, 5]) from checkpoint, the shape in current model is torch.Size([96, 96, 5, 5]).\n\tsize mismatch for conv2a.weights: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([16896]).\n\tsize mismatch for conv2a.filter: copying a param with shape torch.Size([16, 6, 5, 5]) from checkpoint, the shape in current model is torch.Size([256, 96, 5, 5]).\n\tsize mismatch for conv2b.weights: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([45056]).\n\tsize mismatch for conv2b.filter: copying a param with shape torch.Size([16, 16, 5, 5]) from checkpoint, the shape in current model is torch.Size([256, 256, 5, 5]).\n\tsize mismatch for conv2c.weights: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([45056]).\n\tsize mismatch for conv2c.filter: copying a param with shape torch.Size([16, 16, 5, 5]) from checkpoint, the shape in current model is torch.Size([256, 256, 5, 5]).\n\tsize mismatch for conv3a.weights: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([90112]).\n\tsize mismatch for conv3a.filter: copying a param with shape torch.Size([32, 16, 5, 5]) from checkpoint, the shape in current model is torch.Size([512, 256, 5, 5]).\n\tsize mismatch for conv3b.weights: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([180224]).\n\tsize mismatch for conv3b.filter: copying a param with shape torch.Size([32, 32, 5, 5]) from checkpoint, the shape in current model is torch.Size([512, 512, 5, 5]).\n\tsize mismatch for conv3c.weights: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([180224]).\n\tsize mismatch for conv3c.filter: copying a param with shape torch.Size([32, 32, 5, 5]) from checkpoint, the shape in current model is torch.Size([512, 512, 5, 5]).\n\tsize mismatch for conv4a.weights: copying a param with shape torch.Size([6144]) from checkpoint, the shape in current model is torch.Size([360448]).\n\tsize mismatch for conv4a.filter: copying a param with shape torch.Size([64, 32, 5, 5]) from checkpoint, the shape in current model is torch.Size([1024, 512, 5, 5]).\n\tsize mismatch for conv4b.weights: copying a param with shape torch.Size([12288]) from checkpoint, the shape in current model is torch.Size([720896]).\n\tsize mismatch for conv4b.filter: copying a param with shape torch.Size([64, 64, 5, 5]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 5, 5])."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "configs = [\n",
    "    #\"scaife2021mirabest.cfg\", # Fully Evaluated\n",
    "    #\"scaife2021mirabest-RandAug.cfg\", # Fully Evaluated\n",
    "    #\"scaife2021mirabest-RestrictedAug.cfg\", # Fully Evaluated\n",
    "    #\"scaife2021mingo.cfg\", # Fully Evaluated\n",
    "    #\"scaife2021mingo-RandAug.cfg\", # Fully Evaluated\n",
    "    #\"scaife2021mingo-RestrictedAug.cfg\", # Fully Evaluated\n",
    "    \n",
    "    #\"bowles2021mirabest.cfg\", # Fully Evaluated\n",
    "    #\"bowles2021mirabest-RandAug.cfg\", # Fully Evaluated\n",
    "    #\"bowles2021mirabest-RestrictedAug.cfg\", # Fully Evaluated\n",
    "    #\"bowles2021mingo.cfg\", # Fully Evaluated\n",
    "    #\"bowles2021mingo-RandAug.cfg\", # Fully Evaluated\n",
    "    #\"bowles2021mingo-RestrictedAug.cfg\", # Fully Evaluated\n",
    "    \n",
    "    #\"e2attentionmirabest.cfg\", # Fully Evaluated\n",
    "    #\"e2attentionmirabest-RandAug.cfg\", # Fully Evaluated\n",
    "    #\"e2attentionmirabest-RestrictedAug.cfg\", # Fully Evaluated\n",
    "    #\"e2attentionmingo.cfg\", # Fully Evaluated\n",
    "    #\"e2attentionmingo-RandAug.cfg\", # Fully Evaluated\n",
    "    #\"e2attentionmingo-RestrictedAug.cfg\", # Fully Evaluated\n",
    "    \n",
    "    #\"5kernel_e2attentionmirabest.cfg\",\n",
    "    #\"5kernel_e2attentionmirabest-RandAug.cfg\", # Fully Evaluated\n",
    "    #\"5kernel_e2attentionmirabest-RestrictedAug.cfg\",\n",
    "    #\"5kernel_e2attentionmingo.cfg\",\n",
    "    #\"5kernel_e2attentionmingo-RandAug.cfg\", # Fully Evaluated\n",
    "    #\"5kernel_e2attentionmingo-RestrictedAug.cfg\",\n",
    "    \n",
    "    #\"7kernel_e2attentionmirabest.cfg\",\n",
    "    #\"7kernel_e2attentionmirabest-RandAug.cfg\", # Fully Evaluated\n",
    "    #\"7kernel_e2attentionmirabest-RestrictedAug.cfg\",\n",
    "    #\"7kernel_e2attentionmingo.cfg\",\n",
    "    #\"7kernel_e2attentionmingo-RandAug.cfg\", # Fully Evaluated\n",
    "    #\"7kernel_e2attentionmingo-RestrictedAug.cfg\",\n",
    "    \n",
    "    \"C4_attention_mirabest.cfg\", # Fully Evaluted to: '/raid/scratch/mbowles/EquivariantSelfAttention/models/e2attention/mirabest/fisher/'\n",
    "    \"C8_attention_mirabest.cfg\",\n",
    "    \"C16_attention_mirabest.cfg\",\n",
    "    \"D4_attention_mirabest.cfg\", # Fully Evaluted to: '/raid/scratch/mbowles/EquivariantSelfAttention/models/e2attention/mirabest/fisher/'\n",
    "    \"D8_attention_mirabest.cfg\",\n",
    "    #\"D16_attention_mirabest.cfg\",\n",
    "]\n",
    "\n",
    "data_configs = [\n",
    "    \"e2attentionmirabest.cfg\", # Mirabest Dataset - MBFR\n",
    "    \"e2attentionmingo.cfg\" # Mingo Dataset - MLFR\n",
    "]\n",
    "augmentations = [\n",
    "    #\"rotation and flipping\",\n",
    "    \"random rotation\",\n",
    "    #\"restricted random rotation\"\n",
    "]\n",
    "\n",
    "for cfg in configs:\n",
    "    print(cfg)\n",
    "    config = ConfigParser.ConfigParser(allow_no_value=True)\n",
    "    data_config = ConfigParser.ConfigParser(allow_no_value=True)\n",
    "    config.read('configs/'+cfg)\n",
    "    csv_path = config['output']['directory'] +'/'+ config['data']['augment'] +'/'+ config['output']['training_evaluation']\n",
    "    df = pd.read_csv(csv_path)\n",
    "    best = df.iloc[list(df['validation_update'])].iloc[-1]\n",
    "    \n",
    "    # Extract models kernel size\n",
    "    if config.has_option('model', 'kernel_size'):\n",
    "        kernel_size = config.getint('model', 'kernel_size')\n",
    "    elif \"LeNet\" in config['model']['base']:\n",
    "        kernel_size = 5\n",
    "    else:\n",
    "        kernel_size = 3\n",
    "    \n",
    "    net = locals()[config['model']['base']](**config['model']).to(device)\n",
    "    \n",
    "    \n",
    "    for d_cfg in data_configs:\n",
    "        for augmentation in augmentations:\n",
    "            path_supliment = config['data']['augment']+'/'\n",
    "            model = utils.utils.load_model(config, load_model='best', device=device, path_supliment=path_supliment)\n",
    "            data_config.read('configs/'+d_cfg)\n",
    "            print(f\"Evaluating {cfg}: {config['output']['directory']}/{config['data']['augment']}\\t{data_config['data']['dataset']}\\t{augmentation}\")\n",
    "            data  = utils.data.load(\n",
    "                data_config,\n",
    "                train=False,\n",
    "                augmentation=augmentation, \n",
    "                data_loader=True\n",
    "            )\n",
    "            \n",
    "            y_pred, y_labels = utils.evaluation.predict(\n",
    "                model, \n",
    "                data, \n",
    "                augmentation_loops=100, \n",
    "                raw_predictions=True\n",
    "            )\n",
    "            \n",
    "            utils.evaluation.save_evaluation(\n",
    "                y_pred, \n",
    "                y_labels,\n",
    "                model_name=config['model']['base'],\n",
    "                kernel_size=kernel_size,\n",
    "                train_data=config['data']['dataset'],\n",
    "                train_augmentation=config['data']['augment'],\n",
    "                test_data=data_config['data']['dataset'],\n",
    "                test_augmentation=augmentation,\n",
    "                epoch=int(best.name),\n",
    "                best=True,\n",
    "                raw=False,\n",
    "                PATH='/raid/scratch/mbowles/EquivariantSelfAttention/models/e2attention/mirabest/fisher/'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-samoa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
