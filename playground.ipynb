{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "documented-series",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in testNet\n",
      "testNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=20736, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#import e2cnn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import PIL\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import configparser as ConfigParser\n",
    "\n",
    "import utils\n",
    "# Ipmport various network architectures\n",
    "from networks import AGRadGalNet, VanillaLeNet, testNet #, DNSteerableLeNet #e2cnn module only works in python3.7+\n",
    "# Import various data classes\n",
    "from datasets import FRDEEPF\n",
    "from datasets import MiraBest_full, MBFRConfident, MBFRUncertain, MBHybrid\n",
    "from datasets import MingoLoTSS, MLFR, MLFRTest\n",
    "\n",
    "# Set seeds for reproduceability\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Get correct device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "#print(device)\n",
    "# Read in config file\n",
    "config_name = [\"bowles2021mirabest.cfg\", \n",
    "               \"bowles2021LoTSS.cfg\", \n",
    "               \"scaife2021mirabestDN.cfg\", \n",
    "               \"scaife2021mirabestVanilla.cfg\"\n",
    "              ]\n",
    "config_name = \"configs/\"+config_name[3]\n",
    "config = ConfigParser.ConfigParser(allow_no_value=True)\n",
    "config.read(config_name)\n",
    "\n",
    "# Load network architecture (with random weights)\n",
    "print(f\"Loading in {config['model']['base']}\")\n",
    "net = locals()[config['model']['base']](**config['model']).to(device)\n",
    "print(net)\n",
    "print(torch.cuda.get_device_name(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "short-reflection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "limiting-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Create data transformations\n",
    "datamean = config.getfloat('data', 'datamean')\n",
    "datastd = config.getfloat('data', 'datastd')\n",
    "number_rotations = config.getint('data', 'number_rotations')\n",
    "imsize = config.getint('data', 'imsize')\n",
    "scaling_factor = config.getfloat('data', 'scaling')\n",
    "angles = np.linspace(0, 359, config.getint('data', 'number_rotations'))\n",
    "p_flip = 0.5 if config.getboolean('data','flip') else 0\n",
    "\n",
    "# Create hard random (seeded) rotation:\n",
    "class RotationTransform:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "    def __init__(self, angles, interpolation):\n",
    "        self.angles = angles\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, x):\n",
    "        angle = np.random.choice(a=self.angles, size=1)[0]\n",
    "        return transforms.functional.rotate(x, angle, interpolation=self.interpolation)\n",
    "\n",
    "\n",
    "# Compose dict of transformations\n",
    "transformations = {\n",
    "    'none': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([datamean],[datastd])\n",
    "    ]),\n",
    "    'rotation and flipping': transforms.Compose([\n",
    "        transforms.CenterCrop(imsize),\n",
    "        transforms.RandomVerticalFlip(p=p_flip),\n",
    "        RotationTransform(angles, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0, # No uncontrolled rotation\n",
    "            scale=(1-scaling_factor, 1+scaling_factor), \n",
    "            interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([datamean],[datastd])\n",
    "    ]),\n",
    "    'no rotation no flipping': transforms.Compose([\n",
    "        transforms.CenterCrop(imsize),\n",
    "        transforms.RandomVerticalFlip(p=p_flip),\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0, # No uncontrolled rotation\n",
    "            scale=(1-scaling_factor, 1+scaling_factor), \n",
    "            interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([datamean],[datastd])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Read / Create Folder for Data to be Saved\n",
    "root = config['data']['directory']\n",
    "os.makedirs(root, exist_ok=True)\n",
    "download = True\n",
    "train = True\n",
    "data_class = locals()[config['data']['dataset']]\n",
    "data_set = data_class(root=root, download=download, train=train, transform=transformations['rotation and flipping'])\n",
    "\n",
    "# Seperate Data into Subsets for Training, Validation, Testing.\n",
    "train_data = data_class(root=root, download=download, train=True, transform=transformations['rotation and flipping'])\n",
    "test_data = data_class(root=root, download=download, train=False, transform=transformations['rotation and flipping'])\n",
    "\n",
    "#train_batched = torch.utils.data.DataLoader(traindata, batch_size=config.getint('training', 'batch_size'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data parameters\n",
    "batch_size = config.getint('training', 'batch_size')\n",
    "validation_size = config.getfloat('training', 'validation_set_size')\n",
    "dataset_size = len(train_data)\n",
    "nval = int(validation_size*dataset_size)\n",
    "indices = list(range(dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[nval:], indices[:nval]\n",
    "\n",
    "train_sampler = torch.utils.data.Subset(train_data, train_indices)\n",
    "valid_sampler = torch.utils.data.Subset(train_data, val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_sampler, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_sampler, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elder-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = config.getfloat('training', 'learning_rate')\n",
    "optimizers = {\n",
    "    'SGD': optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9),\n",
    "    'Adagrad': optim.Adagrad(net.parameters(), lr=learning_rate),\n",
    "    'Adadelta': optim.Adadelta(net.parameters(), lr=learning_rate),\n",
    "    'Adam': optim.Adam(net.parameters(), lr=learning_rate)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rotary-frank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.034678 -0.08857143\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_NOT_INITIALIZED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b279cce71eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbinary_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/scratch/mbowles/EquivariantSelfAttention/networks/e2Nets.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m#x = x*mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 395\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"
     ]
    }
   ],
   "source": [
    "augmentation_loops = config.getint('data', 'number_rotations')\n",
    "if config.getboolean('data', 'flip'):\n",
    "    augmentation_loops = augmentation_loops*2\n",
    "save_validation_updates = True\n",
    "class_splitting_index = 1\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optim_name = config['training']['optimizer']\n",
    "optimizer = optimizers[optim_name]\n",
    "training_results = {\n",
    "    'train_loss': 0,\n",
    "    'validation_loss': 0,\n",
    "    'TP': 0,\n",
    "    'FP': 0,\n",
    "    'FN': 0,\n",
    "    'TN': 0,\n",
    "    'validation_update': False\n",
    "}\n",
    "df = pd.DataFrame(columns = list(training_results.keys()))\n",
    "folder_name = config['output']['directory']\n",
    "output_evaluation_path = config['output']['training_evaluation']\n",
    "output_models_path = config['output']['model_file']\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Variable selections\n",
    "validation_loss_min = np.Inf\n",
    "Epoch = config.getint('training', 'epochs')\n",
    "for epoch_count in range(Epoch):\n",
    "\n",
    "    # Model Training\n",
    "    train_loss = 0.\n",
    "    validation_loss = 0.\n",
    "    confussion_matrix = np.zeros((2,2))\n",
    "    net.train() #Set network to train mode.\n",
    "    if 'binary_labels' in locals():\n",
    "        del binary_labels\n",
    "    if 'outputs' in locals():\n",
    "        del outputs\n",
    "\n",
    "    # Loop across random data augmentations\n",
    "    for i in range(augmentation_loops):\n",
    "        for batch_idx , (data, labels) in enumerate(train_loader): #Iterates through each batch.\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Create binary labels to remove morphological subclassifications (for MiraBest)\n",
    "            binary_labels = np.zeros(labels.size(), dtype=int)\n",
    "            binary_labels = np.where(labels.cpu().numpy()<class_splitting_index, binary_labels, binary_labels+1)\n",
    "            binary_labels = torch.from_numpy(binary_labels).to(device)\n",
    "            \n",
    "            print(data.cpu().numpy().max(), data.cpu().numpy().min())\n",
    "\n",
    "            pred = net.forward(data)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_function(pred,binary_labels)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            train_loss += (loss.item()*data.size(0))\n",
    "\n",
    "\n",
    "    ### Model Validation ###\n",
    "    net.eval()\n",
    "    for epoch_valid in range(augmentation_loops):\n",
    "        for batch_idx, (data, labels) in enumerate(valid_loader):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Create binary labels to remove morphological subclassifications\n",
    "            binary_labels = np.zeros(labels.size(), dtype=int)\n",
    "            binary_labels = np.where(labels.cpu().numpy()<class_splitting_index, binary_labels, binary_labels+1)\n",
    "            binary_labels = torch.from_numpy(binary_labels).to(device)\n",
    "\n",
    "            outputs = net.forward(data)\n",
    "            loss = loss_function(outputs, binary_labels)\n",
    "            validation_loss += (loss.item()*data.size(0))\n",
    "            \n",
    "            predictions = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "            target_values = binary_labels.detach().cpu().numpy()\n",
    "            for x, y in zip(predictions, target_values):\n",
    "                confussion_matrix[x,y] += 1\n",
    "\n",
    "    # Average losses (scaled according to validation dataset size)\n",
    "    validation_loss = validation_loss/(len(valid_loader.dataset)*augmentation_loops)\n",
    "    train_loss = train_loss/(len(train_loader.dataset)*augmentation_loops)\n",
    "    training_results['train_loss'] = train_loss\n",
    "    training_results['validation_loss'] = validation_loss\n",
    "    #training_results['validation_confussion_matrix'] = confussion_matrix\n",
    "    training_results['TP'] = confussion_matrix[0,0]\n",
    "    training_results['FP'] = confussion_matrix[0,1]\n",
    "    training_results['FN'] = confussion_matrix[1,0]\n",
    "    training_results['TN'] = confussion_matrix[1,1]\n",
    "\n",
    "    # Print\n",
    "    print(f\"Epoch:{epoch_count:3}\\tTraining Loss: {training_results['train_loss']:8.6f}\\t\\tValidation Loss: {training_results['validation_loss']:8.6f}\")\n",
    "\n",
    "    # Save model if validation loss decreased\n",
    "    if validation_loss <= validation_loss_min:\n",
    "        print(f\"\\tValidation Loss Down: \\t({validation_loss_min:8.6f}-->{validation_loss:8.6f}) ... Updating saved model.\")\n",
    "        training_results['validation_update'] = True\n",
    "        if save_validation_updates:\n",
    "            torch.save(net.state_dict(), f\"{folder_name}/{epoch_count}.pt\")\n",
    "        else:\n",
    "            torch.save(net.state_dict(), f\"{folder_name}/{output_models_path}\")\n",
    "        validation_loss_min = validation_loss\n",
    "    else:\n",
    "        training_results['validation_update'] = False\n",
    "\n",
    "    \n",
    "    # Save training loss / validation loss for plotting\n",
    "    df = df.append(training_results, ignore_index=True)\n",
    "\n",
    "\n",
    "df.to_csv(f'{folder_name}/{output_evaluation_path}', index=False)\n",
    "print(f\"\\nFinished training.\\nMinimum Validation Loss: {validation_loss_min:8.6}\\n\")\n",
    "\n",
    "# Save final model, no matter the loss\n",
    "torch.save(net.state_dict(), f'{folder_name}/last.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "suspended-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_NOT_INITIALIZED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5239688250a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/scratch/mbowles/EquivariantSelfAttention/networks/SelfAttention_Bowles2021.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Define forward pass:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mconv1a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbnorm1a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#1->6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mconv1b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbnorm1b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#6->6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mconv1c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbnorm1c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#6->6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid/scratch/mbowles/EquivariantSelfAttention/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 395\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"
     ]
    }
   ],
   "source": [
    "outputs = net.forward(data)\n",
    "print(outputs)\n",
    "print(np.argmax(outputs.detach().cpu().numpy(), axis=1))\n",
    "print(binary_labels.cpu().numpy())\n",
    "img = data[3].cpu().numpy().squeeze()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confussion_matrix)\n",
    "plt.imshow(confussion_matrix, cmap='Blues')\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.xticks([0,1],['FRI','FRII'])\n",
    "plt.yticks([0,1],['FRI','FRII'])\n",
    "plt.show()\n",
    "print(confussion_matrix.sum())\n",
    "print(len(train_data)*0.2*16*2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "reflected-insight",
   "metadata": {},
   "source": [
    "count = 0\n",
    "for data, label in traindata:\n",
    "    count+=1\n",
    "print(count)\n",
    "\n",
    "for d in trainset:\n",
    "    print(d)\n",
    "    break\n",
    "\n",
    "print(traindata.data.shape)\n",
    "print(len(traindata.targets))\n",
    "print(traindata[10:100][0].shape)\n",
    "plt.imshow(traindata[0][0].squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "capital-finance",
   "metadata": {},
   "source": [
    "counter = 0\n",
    "for data, label in traindata:\n",
    "    counter+=1\n",
    "    plt.imshow(np.asarray(data)[0])\n",
    "    plt.title(['FRI','FRII'][label])\n",
    "    plt.show()\n",
    "    if counter>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "stock-cleanup",
   "metadata": {},
   "source": [
    "class Model:\n",
    "    def __init__(self, configfile):\n",
    "        # Read in the config file\n",
    "        self.config_name = configfile\n",
    "        self.config = ConfigParser.SafeConfigParser(allow_no_value=True)\n",
    "        self.config.read(self.config_name)\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.net = utils.net.load(\n",
    "            device=self.device, \n",
    "            **self.config['model'])\n",
    "        self.data = utils.data.load(\n",
    "            device=self.device, \n",
    "            rotations=self.config.getint('model', 'number_rotations'), \n",
    "            **self.config['data'])\n",
    "        self.train = utils.train.load(self.config_name)\n",
    "        \n",
    "        self.model_trained = self.config.getboolean('grid_search', 'done')\n",
    "        \n",
    "\n",
    "    def model_trained(self):\n",
    "        if self.config.getboolean('grid_search', 'done'):\n",
    "            print('Training not required')\n",
    "        else:\n",
    "            print('Training required')\n",
    "\n",
    "test_net = Model('configs/template.cfg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-label",
   "metadata": {},
   "source": [
    "Data Manipulation:\n",
    "- path_to_model(file_name)\n",
    "- data_call(dataset_name)\n",
    "- determine_dataset(dataset,model_name) ... dataset in ['automatic','FRDEEP-F','MiraBest']\n",
    "\n",
    "Model Manipulation:\n",
    "- load_net(model_name,device)\n",
    "- training_validation(PATH,xlims=[None,None],save=False,full_path=False) ... PATH is a local title of a folder or file (within ./TrainedNetworks)\n",
    "- prediction(dataset, net, class_groups,(device='cuda',reps='360'))\n",
    "- evaluate(file_name, dataset='automatic')\n",
    "\n",
    "Evaluation Plots:\n",
    "- plot_conf_mat(conf_matrix,normalised=True,n_classes=2,format_input=None,title='Confusion Matrix')\n",
    "- plot_roc_curve(fpr,tpr,title='ROC Curve (AUC=\\{auc:.3f\\})')\n",
    "- out_print(out)\n",
    "\n",
    "Attention Maps:\n",
    "- attentions_func(batch_of_images, net, mean=True, device=torch.device('cpu'))\n",
    "- attention_analysis(source, source_only=True, attention_maps=None, GradCAM=None)\n",
    "- AttentionImagesByEpoch(sources, folder_name, net,epoch=1500, device=torch.device('cpu'))\n",
    "- attention_epoch_plot(source_images,folder_name, logged=False, width=3, device=torch.device('cpu'))\n",
    "\n",
    "GradCAM:\n",
    "- To be completed.\n",
    "\n",
    "Other:\n",
    "- mask_on_image(img, mask)\n",
    "- SortedDataSamples(data_name, transformed=True,  rotations=1, subset='NOHYBRID')\n",
    "- net_name_extraction(PATH)\n",
    "\n",
    "Incomplete:\n",
    "- Loading from Pickled dicts\n",
    "- GradCAM Call for a given image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "alive-rabbit",
   "metadata": {},
   "source": [
    "lr = model.config['grid_search']['learning_rate'].split(',')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-engineer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
